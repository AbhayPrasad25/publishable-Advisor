The Importance of Written Explanations in
Aggregating Crowdsourced Predictions
Abstract
Thisstudydemonstratesthatincorporatingthewrittenexplanationsprovidedby
individualswhenmakingpredictionsenhancestheaccuracyofaggregatedcrowd-
sourced forecasts. The research shows that while majority and weighted vote
methods are effective, the inclusion of written justifications improves forecast
accuracythroughoutmostofaquestion’sduration,withtheexceptionofitsfinal
phase. Furthermore,thestudyanalyzestheattributesthatdifferentiatereliableand
unreliablejustifications.
1 Introduction
Theconceptofthe"wisdomofthecrowd"positsthatcombininginformationfromnumerousnon-
expertindividualscanproduceanswersthatareasaccurateas,orevenmoreaccuratethan,those
providedbyasingleexpert. Aclassicexampleofthisconceptistheobservationthatthemedian
estimateofanox’sweightfromalargegroupoffairattendeeswasremarkablyclosetotheactual
weight. While generally supported, the idea is not without its limitations. Historical examples
demonstrateinstanceswherecrowdsbehavedirrationally,andevenaworldchesschampionwasable
todefeatthecombinedmovesofacrowd.
Inthecurrentera,theadvantagesofcollectiveintelligencearewidelyutilized.Forexample,Wikipedia
reliesonthecontributionsofvolunteers,andcommunity-drivenquestion-answeringplatformshave
garnered significant attention from the research community. When compiling information from
largegroups,itisimportanttodeterminewhethertheindividualinputsweremadeindependently. If
not,factorslikegrouppsychologyandtheinfluenceofpersuasiveargumentscanskewindividual
judgments,thusnegatingthepositiveeffectsofcrowdwisdom.
This paper focuses on forecasts concerning questions spanning political, economic, and social
domains. Eachforecastincludesaprediction,estimatingtheprobabilityofaparticularevent,and
a written justification that explains the reasoning behind the prediction. Forecasts with identical
predictionscanhavejustificationsofvaryingstrength,which,inturn,affectstheperceivedreliability
of the predictions. For instance, a justification that simply refers to an external source without
explanationmayappeartorelyheavilyontheprevailingopinionofthecrowdandmightbeconsidered
weakerthanajustificationthatpresentsspecific,verifiablefactsfromexternalresources.
Toclarifytheterminologyused: a"question"isdefinedasastatementthatseeksinformation(e.g.,
"Willnewlegislationbeimplementedbeforeacertaindate?"). Questionshaveadefinedstartand
enddate, andtheperiodbetweenthesedatesconstitutesthe"life"ofthequestion. "Forecasters"
areindividualswhoprovidea"forecast,"whichconsistsofa"prediction"anda"justification."The
predictionisanumericalrepresentationofthelikelihoodofaneventoccurring. Thejustification
isthetextprovidedbytheforecastertosupporttheirprediction. Thecentralproblemaddressedin
thisworkistermed"callingaquestion,"whichreferstotheprocessofdeterminingafinalprediction
by aggregating individual forecasts. Two strategies are employed for calling questions each day
throughouttheirlife: consideringforecastssubmittedonthegivenday("daily")andconsideringthe
lastforecastsubmittedbyeachforecaster("active").Inspiredbypriorresearchonrecognizingandfosteringskilledforecasters,andanalyzingwritten
justificationstoassessthequalityofindividualorcollectiveforecasts, thispaperinvestigatesthe
automatedcallingofquestionsthroughouttheirdurationbasedontheforecastsavailableeachday.
Theprimarycontributionsareempiricalfindingsthataddressthefollowingresearchquestions:
*Whenmakingapredictiononaspecificday,isitadvantageoustoincludeforecastsfromprevious
days? (Yes) * Does the accuracy of the prediction improve when considering the question itself
andthewrittenjustificationsprovidedwiththeforecasts? (Yes)*Isiteasiertomakeanaccurate
predictiontowardtheendofaquestion’sduration? (Yes)*Arewrittenjustificationsmorevaluable
whenthecrowd’spredictionsarelessaccurate? (Yes)
Inaddition,thisresearchpresentsanexaminationofthejustificationsassociatedwithbothaccurate
andinaccurateforecasts. Thisanalysisaimstoidentifythefeaturesthatcontributetoajustification
beingmoreorlesscredible.
2 RelatedWork
Thelanguageemployedbyindividualsisindicativeofvariouscharacteristics. Priorresearchincludes
bothpredictivemodels(usinglanguagesamplestopredictattributesabouttheauthor)andmodels
thatprovidevaluableinsights(usinglanguagesamplesandauthorattributestoidentifydifferentiating
linguisticfeatures). Previousstudieshaveexaminedfactorssuchasgenderandage,politicalideology,
healthoutcomes,andpersonalitytraits. Inthispaper,modelsareconstructedtopredictoutcomes
basedoncrowd-sourcedforecastswithoutknowledgeofindividualforecasters’identities.
Previousresearchhasalsoexploredhowlanguageusevariesdependingontherelationshipsbetween
individuals. Forinstance,studieshaveanalyzedlanguagepatternsinsocialnetworks,onlinecommu-
nities,andcorporateemailstounderstandhowindividualsinpositionsofauthoritycommunicate.
Similarly,researchershaveexaminedhowlanguageprovidesinsightsintointerpersonalinteractions
andrelationships. Intermsoflanguageformandfunction,priorresearchhasinvestigatedpoliteness,
empathy, advice, condolences, usefulness, and deception. Related to the current study’s focus,
researchershaveexaminedtheinfluenceofWikipediaeditorsandstudiedinfluencelevelswithin
onlinecommunities. Persuasionhasalsobeenanalyzedfromacomputationalperspective,including
withinthecontextofdialoguesystems. Theworkpresentedherecomplementsthesepreviousstudies.
Thegoalistoidentifycrediblejustificationstoimprovetheaggregationofcrowdsourcedforecasts,
withoutexplicitlytargetinganyoftheaforementionedcharacteristics.
Withinthefieldofcomputationallinguistics,thetaskmostcloselyrelatedtothisresearchisargumen-
tation. Astrongjustificationforaforecastcanbeconsideredawell-reasonedsupportingargument.
Previous work in this area includes identifying argument components such as claims, premises,
backing,rebuttals,andrefutations,aswellasminingargumentsthatsupportoropposeaparticular
claim. Despite these efforts, it was found that crowdsourced justifications rarely adhere to these
establishedargumentationframeworks,eventhoughsuchjustificationsarevaluableforaggregating
forecasts.
Finally,severalstudieshavefocusedonforecastingusingdatasetssimilaroridenticaltotheoneused
inthisresearch. Fromapsychologicalperspective,researchershaveexploredstrategiesforenhancing
forecastingaccuracy,suchasutilizingtop-performingforecasters(oftencalled"superforecasters"),
andhaveanalyzedthetraitsthatcontributetotheirsuccess.Thesestudiesaimtoidentifyandcultivate
superforecastersbutdonotincorporatethewrittenjustificationsaccompanyingforecasts. Incontrast,
the present research develops models to call questions without using any information about the
forecastersthemselves. Withinthefieldofcomputationallinguistics,researchershaveevaluatedthe
languageusedinhigh-qualityjustifications,focusingonaspectslikerating,benefit,andinfluence.
Otherresearchershavedevelopedmodelstopredictforecasterskillusingthetextualjustifications
fromspecificdatasets,suchastheGoodJudgmentOpendata,andhavealsoappliedthesemodels
topredicttheaccuracyofindividualforecastsinothercontexts,suchascompanyearningsreports.
However,noneofthesepriorworkshavespecificallyaimedtocallquestionsthroughouttheirentire
duration.
23 Dataset
TheresearchutilizesdatafromtheGoodJudgmentOpen,aplatformwherequestionsareposted,and
individualssubmittheirforecasts. Thequestionsprimarilyrevolvearoundgeopolitics,encompassing
areassuchasdomesticandinternationalpolitics,theeconomy,andsocialmatters. Forthisstudy,all
binaryquestionswerecollected,alongwiththeirassociatedforecasts,eachcomprisingaprediction
and a justification. In total, the dataset contains 441 questions and 96,664 forecasts submitted
over32,708days. Thisdatasetsignificantlyexpandsuponpreviousresearch,nearlydoublingthe
numberofforecastsanalyzed. Sincetheobjectiveistoaccuratelycallquestionsthroughouttheir
entireduration,allforecastswithwrittenjustificationsareincluded,regardlessoffactorssuchas
justificationlengthorthenumberofforecastssubmittedbyasingleforecaster. Additionally,this
approachprioritizesprivacy,asnoinformationabouttheindividualforecastersisutilized.
Table1: Analysisofthequestionsfromourdataset. Mostquestionsarerelativelylong,containtwo
ormorenamedentities,andareopenforoveronemonth.
Metric Min Q1 Q2(Median) Q3 Max Mean
#tokens 8 16 20 28 48 21.94
#entities 0 2 3 5 11 3.47
#verbs 0 2 2 3 6 2.26
#daysopen 2 24 59 98 475 74.16
Table 1 provides a basic analysis of the questions in the dataset. The majority of questions are
relativelylengthy,containingmorethan16tokensandmultiplenamedentities,withgeopolitical,
person,anddateentitiesbeingthemostfrequent. Intermsofduration,halfofthequestionsremain
openfornearlytwomonths,and75%areopenformorethanthreeweeks.
An examination of the topics covered by the questions using Latent Dirichlet Allocation (LDA)
revealsthreeprimarythemes: elections(includingtermslike"voting,""winners,"and"candidate"),
governmentactions(includingtermslike"negotiations,""announcements,""meetings,"and"passing
(alaw)"),andwarsandviolentcrimes(includingtermslike"groups,""killing,""civilian(casualties),"
and "arms"). Although not explicitly represented in the LDA topics, the questions address both
domesticandinternationaleventswithinthesebroadthemes.
Table2: Analysisofthe96,664writtenjustificationssubmittedbyforecastersinourdataset. The
readabilityscoresindicatethatmostjustificationsareeasilyunderstoodbyhighschoolstudents(11th
or12thgrade),althoughasubstantialamount(>25%)requireacollegeeducation(Fleschunder50or
Dale-Challover9.0).
Min Q1 Q2 Q3 Max
#sentences 1 1 1 3 56
#tokens 1 10 23 47 1295
#entities 0 0 2 4 154
#verbs 0 1 3 6 174
#adverbs 0 0 1 3 63
#adjectives 0 0 2 4 91
#negation 0 0 1 3 69
Sentiment -2.54 0 0 0.20 6.50
Readability
Flesch -49.68 50.33 65.76 80.62 121.22
Dale-Chall 0.05 6.72 7.95 9.20 19.77
Table2presentsafundamentalanalysisofthe96,664forecastjustificationsinthedataset.Themedian
lengthisrelativelyshort,consistingofonesentenceand23tokens. Justificationsmentionnamed
entitieslessfrequentlythanthequestionsthemselves. Interestingly,halfofthejustificationscontain
atleastonenegation,and25%includethreeormore. Thissuggeststhatforecasterssometimesbase
theirpredictionsoneventsthatmightnotoccurorhavenotyetoccurred. Thesentimentpolarityof
3thejustificationsisgenerallyneutral. Intermsofreadability,boththeFleschandDale-Challscores
suggestthatapproximatelyaquarterofthejustificationsrequireacollege-leveleducationforfull
comprehension.
Regardingverbsandnouns,ananalysisusingWordNetlexicalfilesrevealsthatthemostcommon
verbclassesare"change"(e.g.,"happen,""remain,""increase"),"social"(e.g.,"vote,""support,"
"help"),"cognition"(e.g.,"think,""believe,""know"),and"motion"(e.g.,"go,""come,""leave").
Themostfrequentnounclassesare"act"(e.g.,"election,""support,""deal"),"communication"(e.g.,
"questions,""forecast,""news"),"cognition"(e.g.,"point,""issue,""possibility"),and"group"(e.g.,
"government,""people,""party").
4 ExperimentsandResults
Experiments are conducted to address the challenge of accurately calling a question throughout
itsduration. Theinputconsistsofthequestionitselfandtheassociatedforecasts(predictionsand
justifications),whiletheoutputisanaggregatedanswertothequestionderivedfromallforecasts.
The number of instances corresponds to the total number of days all questions were open. Both
simplebaselinesandaneuralnetworkareemployed,consideringboth(a)dailyforecastsand(b)
activeforecastssubmitteduptotendaysprior.
The questions are divided into training, validation, and test subsets. Subsequently, all forecasts
submitted throughout the duration of each question are assigned to their respective subsets. It’s
importanttonotethatrandomlysplittingtheforecastswouldbeaninappropriateapproach. Thisis
becauseforecastsforthesamequestionsubmittedondifferentdayswouldbedistributedacrossthe
training,validation,andtestsubsets,leadingtodataleakageandinaccurateperformanceevaluation.
4.1 Baselines
Twounsupervisedbaselinesareconsidered. The"majorityvote"baselinedeterminestheanswertoa
questionbasedonthemostfrequentpredictionamongtheforecasts. The"weightedvote"baseline,
ontheotherhand,assignsweightstotheprobabilitiesinthepredictionsandthenaggregatesthem.
4.2 NeuralNetworkArchitecture
Aneuralnetworkarchitectureisemployed,whichconsistsofthreemaincomponents:onetogenerate
arepresentationofthequestion,anothertogeneratearepresentationofeachforecast,andanLSTM
toprocessthesequenceofforecastsandultimatelycallthequestion.
TherepresentationofaquestionisobtainedusingBERT,followedbyafullyconnectedlayerwith256
neurons,ReLUactivation,anddropout. Therepresentationofaforecastiscreatedbyconcatenating
threeelements:(a)abinaryflagindicatingwhethertheforecastwassubmittedonthedaythequestion
isbeingcalledoronapreviousday,(b)thepredictionitself(anumericalvaluebetween0.0and1.0),
and(c)arepresentationofthejustification. Therepresentationofthejustificationisalsoobtained
usingBERT,followedbyafullyconnectedlayerwith256neurons,ReLUactivation,anddropout.
TheLSTMhasahiddenstatewithadimensionalityof256andprocessesthesequenceofforecasts
asitsinput. Duringthetuningprocess,itwasdiscoveredthatprovidingtherepresentationofthe
questionalongsideeachforecastismoreeffectivethanprocessingforecastsindependentlyofthe
question. Consequently,therepresentationofthequestionisconcatenatedwiththerepresentationof
eachforecastbeforebeingfedintotheLSTM.Finally,thelasthiddenstateoftheLSTMisconnected
toafullyconnectedlayerwithasingleneuronandsigmoidactivationtoproducethefinalprediction
forthequestion.
4.3 ArchitectureAblation
Experimentsarecarriedoutwiththecompleteneuralarchitecture,asdescribedabove,aswellas
withvariationswherecertaincomponentsaredisabled. Specifically,therepresentationofaforecast
ismanipulatedbyincorporatingdifferentcombinationsofinformation:
4*Onlytheprediction. *Thepredictionandtherepresentationofthequestion. *Thepredictionand
therepresentationofthejustification. *Theprediction,therepresentationofthequestion,andthe
representationofthejustification.
4.4 QuantitativeResults
Theevaluationmetricusedisaccuracy,whichrepresentstheaveragepercentageofdaysamodel
correctlycallsaquestionthroughoutitsduration. Resultsarereportedforalldayscombined,aswell
asforeachofthefourquartilesofthequestion’sduration.
Table3: Resultswiththetestquestions(Accuracy: averagepercentageofdaysamodelpredictsa
questioncorrectly). Resultsareprovidedforalldaysaquestionwasopenandforfourquartiles(Q1:
first25%ofdays,Q2: 25-50%,Q3: 50-75%,andQ4: last25%ofdays).
DaysWhentheQuestionWasOpen
Model AllDays Q1 Q2 Q3 Q4
UsingDailyForecastsOnly
Baselines
MajorityVote(predictions) 71.89 64.59 66.59 73.26 82.22
WeightedVote(predictions) 73.79 67.79 68.71 74.16 83.61
NeuralNetworkVariants
PredictionsOnly 77.96 77.62 77.93 78.23 78.61
Predictions+Question 77.61 75.44 76.77 78.05 81.56
Predictions+Justifications 80.23 77.87 78.65 79.26 84.67
Predictions+Question+Justifications 79.96 78.65 78.11 80.29 83.28
UsingActiveForecasts
Baselines
MajorityVote(predictions) 77.27 68.83 73.92 77.98 87.44
WeightedVote(predictions) 77.97 72.04 72.17 78.53 88.22
NeuralNetworkVariants
PredictionsOnly 78.81 77.31 78.04 78.53 81.11
Predictions+Question 79.35 76.05 78.53 79.56 82.94
Predictions+Justifications 80.84 77.86 79.07 79.74 86.17
Predictions+Question+Justifications 81.27 78.71 79.81 81.56 84.67
Despitetheirrelativesimplicity,thebaselinemethodsachievecommendableresults,demonstrating
thataggregatingforecasterpredictionswithoutconsideringthequestionorjustificationsisaviable
strategy. However,thefullneuralnetworkachievessignificantlyimprovedresults.
**UsingDailyorActiveForecasts**Incorporatingactiveforecasts,ratherthansolelyrelyingon
forecastssubmittedonthedaythequestioniscalled,provesadvantageousforbothbaselinesandall
neuralnetworkconfigurations,exceptfortheoneusingonlypredictionsandjustifications.
**Encoding Questions and Justifications** The neural network that only utilizes the prediction
to represent a forecast surpasses both baseline methods. Notably, integrating the question, the
justification, or both into the forecast representation yields further improvements. These results
indicatethatincorporatingthequestionandforecaster-providedjustificationsintothemodelenhances
theaccuracyofquestioncalling.
**CallingQuestionsThroughoutTheirLife**Whenexaminingtheresultsacrossthefourquartilesof
aquestion’sduration,it’sobservedthatwhileusingactiveforecastsisbeneficialacrossallquartiles
forbothbaselinesandallnetworkconfigurations,theneuralnetworkssurprisinglyoutperformthe
baselinesonlyinthefirstthreequartiles. Inthelastquartile,theneuralnetworksperformsignificantly
worsethanthebaselines. Thissuggeststhatwhilemodelingquestionsandjustificationsisgenerally
helpful,itbecomesdetrimentaltowardtheendofaquestion’slife.Thisphenomenoncanbeattributed
totheincreasingwisdomofthecrowdasmoreevidencebecomesavailableandmoreforecasters
contribute,makingtheiraggregatedpredictionsmoreaccurate.
5Table4: Resultswiththetestquestions,categorizedbyquestiondifficultyasdeterminedbythebest
baselinemodel. Thetablepresentstheaccuracy(averagepercentageofdaysaquestionispredicted
correctly)forallquestionsandforeachquartileofdifficulty: Q1(easiest25%),Q2(25-50%),Q3
(50-75%),andQ4(hardest25%).
QuestionDifficulty(BasedonBestBaseline)
All Q1 Q2 Q3 Q4
UsingActiveForecasts
WeightedVoteBaseline(Predictions) 77.97 99.40 99.55 86.01 29.30
NeuralNetworkwithComponents...
Predictions+Question 79.35 94.58 88.01 78.04 58.73
Predictions+Justifications 80.84 95.71 93.18 79.99 57.05
Predictions+Question+Justifications 81.27 94.17 90.11 78.67 64.41
**Calling Questions Based on Their Difficulty** The analysis is further refined by examining
resultsbasedonquestiondifficulty,determinedbythenumberofdaysthebest-performingbaseline
incorrectlycallsthequestion. Thishelpstounderstandwhichquestionsbenefitmostfromtheneural
networksthatincorporatequestionsandjustifications. However,it’simportanttonotethatcalculating
question difficulty during the question’s active period is not feasible, making these experiments
unrealisticbeforethequestionclosesandthecorrectanswerisrevealed.
Table 4 presents the results for selected models based on question difficulty. The weighted vote
baselinedemonstratessuperiorperformancefor75
5 QualitativeAnalysis
This section provides insights into the factors that make questions more difficult to forecast and
examinesthecharacteristicsofjustificationsassociatedwithincorrectandcorrectpredictions.
**Questions**Ananalysisofthe88questionsinthetestsetrevealedthatquestionscalledincorrectly
onatleastonedaybythebestmodeltendtohaveashorterduration(69.4daysvs. 81.7days)anda
highernumberofactiveforecastsperday(31.0vs. 26.7). Thissuggeststhatthemodel’serrorsalign
withthequestionsthatforecastersalsofindchallenging.
**Justifications**Amanualreviewof400justifications(200associatedwithincorrectpredictions
and200withcorrectpredictions)wasconducted,focusingonthosesubmittedondayswhenthebest
modelmadeanincorrectprediction. Thefollowingobservationsweremade:
* A higher percentage of incorrect predictions (78%) were accompanied by short justifications
(fewerthan20tokens),comparedto65%forcorrectpredictions. Thissupportstheideathatlonger
user-generatedtextoftenindicateshigherquality. *Referencestopreviousforecasts(eitherbythe
sameorotherforecasters,orthecurrentcrowd’sforecast)weremorecommoninjustificationsfor
incorrectpredictions(31.5%)thanforcorrectpredictions(16%). *Alackofalogicalargument
wasprevalentinthejustifications, regardlessoftheprediction’saccuracy. However, itwasmore
frequentinjustificationsforincorrectpredictions(62.5%)thanforcorrectpredictions(47.5%). *
Surprisingly,justificationswithgenericargumentsdidnotclearlydifferentiatebetweenincorrectand
correctpredictions(16.0%vs. 14.5%). *Poorgrammarandspellingortheuseofnon-Englishwere
infrequentbutmorecommoninjustificationsforincorrectpredictions(24.5%)comparedtocorrect
predictions(14.5%).
6 Conclusions
Forecastinginvolvespredictingfutureevents,acapabilityhighlyvaluedbybothgovernmentsand
industriesasitenablesthemtoanticipateandaddresspotentialchallenges. Thisstudyfocuseson
questionsspanningthepolitical,economic,andsocialdomains,utilizingforecastssubmittedbya
crowdofindividualswithoutspecializedtraining. Eachforecastcomprisesapredictionandanatural
languagejustification.
6Theresearchdemonstratesthataggregatingtheweightedpredictionsofforecastersisasolidbaseline
forcallingaquestionthroughoutitsduration. However,modelsthatincorporateboththequestion
andthejustificationsachievesignificantlybetterresults,particularlyduringthefirstthreequartilesof
aquestion’slife. Importantly,themodelsdevelopedinthisstudydonotprofileindividualforecasters
orutilizeanyinformationabouttheiridentities. Thisworklaysthegroundworkforevaluatingthe
credibilityofanonymousforecasts,enablingthedevelopmentofrobustaggregationstrategiesthatdo
notrequiretrackingindividualforecasters.
7